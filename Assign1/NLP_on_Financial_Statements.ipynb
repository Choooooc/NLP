{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Load Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint\n",
    "import project_helper\n",
    "import project_tests\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "from selenium.webdriver import EdgeOptions\n",
    "from parser_10KQ import get_word_list\n",
    "from itertools import islice\n",
    "options = EdgeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--window-size=%s\" % \"3840, 2160\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get S&P500 CIKs\n",
    "Filter the sp500_constituents csv by removing companies that were out after 2017.\n",
    "Use the sp500_constituents permnos to filter sp500_data and get a dictionary of tickers and\n",
    "CIKs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      permno       start      ending\n6      10104  1989-08-03  2022-03-31\n7      10107  1994-06-07  2022-03-31\n11     10138  1999-10-13  2022-03-31\n12     10145  1925-12-31  2022-03-31\n28     10299  2000-04-03  2017-03-10\n...      ...         ...         ...\n2008   93096  2012-12-03  2022-03-31\n2009   93132  2018-10-11  2022-03-31\n2011   93246  2021-03-22  2022-03-31\n2013   93429  2017-03-01  2022-03-31\n2014   93436  2020-12-21  2022-03-31\n\n[627 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>permno</th>\n      <th>start</th>\n      <th>ending</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>10104</td>\n      <td>1989-08-03</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10107</td>\n      <td>1994-06-07</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10138</td>\n      <td>1999-10-13</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10145</td>\n      <td>1925-12-31</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10299</td>\n      <td>2000-04-03</td>\n      <td>2017-03-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2008</th>\n      <td>93096</td>\n      <td>2012-12-03</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>2009</th>\n      <td>93132</td>\n      <td>2018-10-11</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>2011</th>\n      <td>93246</td>\n      <td>2021-03-22</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>2013</th>\n      <td>93429</td>\n      <td>2017-03-01</td>\n      <td>2022-03-31</td>\n    </tr>\n    <tr>\n      <th>2014</th>\n      <td>93436</td>\n      <td>2020-12-21</td>\n      <td>2022-03-31</td>\n    </tr>\n  </tbody>\n</table>\n<p>627 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_constituents = pd.read_csv(\"sp500_constituents.csv\", dtype={\"permno\":int}, index_col=0)\n",
    "sp500_constituents = sp500_constituents[(sp500_constituents[\"ending\"] > \"2017-01-01\")]\n",
    "sp500_constituents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bwayn\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "sp500_data = pd.read_csv(\"sp500_w_addl_id_with_cik.csv\",dtype={\"cik\":str, \"permno\":int})\n",
    "sp500_data = sp500_data[[\"ticker\", \"permno\", \"cik\"]].set_index(\"ticker\")\n",
    "sp500_data = sp500_data[sp500_data[\"permno\"].isin(sp500_constituents[\"permno\"])]\n",
    "sp500_data.drop_duplicates(inplace=True)\n",
    "sp500_data.dropna(inplace=True)\n",
    "cik_lookup = sp500_data.to_dict()[\"cik\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cik_lookup = dict(islice(cik_lookup.items(), 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def chunks(data, SIZE=100):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        yield {k:data[k] for k in islice(it, SIZE)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NWL': '0000814453', 'BBY': '0000764478', 'AIV': '0000922864'}\n"
     ]
    }
   ],
   "source": [
    "for item in chunks(cik_lookup, 3):\n",
    "    print(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWL request successful\n",
      "BBY request successful\n",
      "AIV request successful\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "sec_api = project_helper.SecAPI()\n",
    "example_ticker = \"AMZN\"\n",
    "sec_data = {ticker: [] for ticker in cik_lookup}\n",
    "headers = {'Host': 'www.sec.gov', 'Connection': 'close',\n",
    "           'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "           'X-Requested-With': 'XMLHttpRequest',\n",
    "           'User-Agent': 'ruizhuoj@andrew.cmu.edu'\n",
    "           }\n",
    "endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "base_url_sec = r\"https://www.sec.gov\"\n",
    "for ticker in cik_lookup:\n",
    "    # define our parameters dictionary\n",
    "    param_dict_10k = {'action': 'getcompany',\n",
    "                  'CIK': cik_lookup[ticker],\n",
    "                  'type': '10-k',\n",
    "                  'dateb': '20220101',\n",
    "                  'owner': 'exclude',\n",
    "                  'start': '',\n",
    "                  'output': '',\n",
    "                  'count': '10'}\n",
    "    # request the url, and then parse the response.\n",
    "    response_10k = requests.get(url=endpoint, params=param_dict_10k, headers=headers)\n",
    "    soup_10k = BeautifulSoup(response_10k.content, 'html.parser')\n",
    "    doc_table_10k = soup_10k.find_all('table', class_='tableFile2')\n",
    "    param_dict_10q = {'action': 'getcompany',\n",
    "                  'CIK': cik_lookup[ticker],\n",
    "                  'type': '10-Q',\n",
    "                  'dateb': '20220101',\n",
    "                  'owner': 'exclude',\n",
    "                  'start': '',\n",
    "                  'output': '',\n",
    "                  'count': '20'}\n",
    "    # request the url, and then parse the response.\n",
    "    response_10q = requests.get(url=endpoint, params=param_dict_10q, headers=headers)\n",
    "    soup_10q = BeautifulSoup(response_10q.content, 'html.parser')\n",
    "    doc_table_10q = soup_10q.find_all('table', class_='tableFile2')\n",
    "    #Get 10-Ks\n",
    "    for row in doc_table_10k[0].find_all('tr'):\n",
    "        # find all the columns\n",
    "        cols = row.find_all('td')\n",
    "        # if there are no columns move on to the next row.\n",
    "        if len(cols) != 0:\n",
    "            # grab the text\n",
    "            filing_type = cols[0].text.strip()\n",
    "            filing_date = cols[3].text.strip()\n",
    "            if datetime.strptime(filing_date, '%Y-%m-%d').date() < datetime.strptime(\"2017\", '%Y').date():\n",
    "                pass\n",
    "            else:\n",
    "                filing_numb = cols[4].text.strip()\n",
    "                # find the links\n",
    "                filing_doc_href = cols[1].find('a', {'href': True, 'id': 'documentsbutton'})\n",
    "                filing_int_href = cols[1].find('a', {'href': True, 'id': 'interactiveDataBtn'})\n",
    "                filing_doc_link = base_url_sec + filing_doc_href['href']\n",
    "                sec_data[ticker].append((filing_doc_link, filing_type, filing_date))\n",
    "    #Get 10-Qs\n",
    "    for row in doc_table_10q[0].find_all('tr'):\n",
    "        # find all the columns\n",
    "        cols = row.find_all('td')\n",
    "        # if there are no columns move on to the next row.\n",
    "        if len(cols) != 0:\n",
    "            # grab the text\n",
    "            filing_type = cols[0].text.strip()\n",
    "            filing_date = cols[3].text.strip()\n",
    "            filing_numb = cols[4].text.strip()\n",
    "            # find the links\n",
    "            filing_doc_href = cols[1].find('a', {'href': True, 'id': 'documentsbutton'})\n",
    "            filing_int_href = cols[1].find('a', {'href': True, 'id': 'interactiveDataBtn'})\n",
    "            filing_doc_link = base_url_sec + filing_doc_href['href']\n",
    "            sec_data[ticker].append((filing_doc_link, filing_type, filing_date))\n",
    "    print(ticker, \"request successful\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download 10-ks\n",
    "As you see, this is a list of urls. These urls point to a file that contains metadata related to each filling. Since we don't care about the metadata, we'll pull the filling by replacing the url with the filling url."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import re\n",
    "# Regex to find <DOCUMENT> tags\n",
    "doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
    "# Regex to find <TYPE> tag prceeding any characters, terminating at new line\n",
    "type_pattern = re.compile(r'<TYPE>[^\\n]+')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:   4%|▍         | 1/25 [00:00<00:03,  7.35filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000081445321000050/0000814453-21-000050-index.htm 10-K 2021-02-19\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445320000078/0000814453-20-000078-index.htm 10-K 2020-03-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  12%|█▏        | 3/25 [00:00<00:02,  7.50filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000119312519061714/0001193125-19-061714-index.htm 10-K 2019-03-04\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000119312518067603/0001193125-18-067603-index.htm 10-K 2018-03-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  20%|██        | 5/25 [00:00<00:02,  7.86filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000081445317000027/0000814453-17-000027-index.htm 10-K 2017-03-01\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445321000151/0000814453-21-000151-index.htm 10-Q 2021-10-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  28%|██▊       | 7/25 [00:01<00:03,  5.01filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000081445321000120/0000814453-21-000120-index.htm 10-Q 2021-07-30\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445321000072/0000814453-21-000072-index.htm 10-Q 2021-04-30\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445320000230/0000814453-20-000230-index.htm 10-Q 2020-10-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  40%|████      | 10/25 [00:01<00:02,  6.97filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000081445320000215/0000814453-20-000215-index.htm 10-Q 2020-08-05\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445320000114/0000814453-20-000114-index.htm 10-Q 2020-05-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  48%|████▊     | 12/25 [00:02<00:02,  4.40filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000081445319000111/0000814453-19-000111-index.htm 10-Q 2019-11-04\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000162828019009873/0001628280-19-009873-index.htm 10-Q 2019-08-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  56%|█████▌    | 14/25 [00:02<00:01,  5.78filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000119312519141536/0001193125-19-141536-index.htm 10-Q 2019-05-08\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000119312518323823/0001193125-18-323823-index.htm 10-Q 2018-11-09\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000119312518244528/0001193125-18-244528-index.htm 10-Q 2018-08-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  72%|███████▏  | 18/25 [00:03<00:01,  5.77filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000119312518159187/0001193125-18-159187-index.htm 10-Q 2018-05-10\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000119312517337345/0001193125-17-337345-index.htm 10-Q 2017-11-08\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000119312517252867/0001193125-17-252867-index.htm 10-Q 2017-08-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  80%|████████  | 20/25 [00:03<00:00,  7.04filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000119312517166044/0001193125-17-166044-index.htm 10-Q 2017-05-10\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445316000273/0000814453-16-000273-index.htm 10-Q 2016-11-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings:  88%|████████▊ | 22/25 [00:04<00:00,  4.55filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000081445316000258/0000814453-16-000258-index.htm 10-Q 2016-08-09\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445316000202/0000814453-16-000202-index.htm 10-Q 2016-05-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading NWL Fillings: 100%|██████████| 25/25 [00:04<00:00,  5.48filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/814453/000081445315000131/0000814453-15-000131-index.htm 10-Q 2015-11-09\n",
      "https://www.sec.gov/Archives/edgar/data/814453/000081445315000108/0000814453-15-000108-index.htm 10-Q 2015-08-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading BBY Fillings:   0%|          | 0/25 [00:00<?, ?filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447821000024/0000764478-21-000024-index.htm 10-K 2021-03-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:   8%|▊         | 2/25 [00:00<00:08,  2.80filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447820000017/0000764478-20-000017-index.htm 10-K 2020-03-23\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447819000009/0000764478-19-000009-index.htm 10-K 2019-03-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  16%|█▌        | 4/25 [00:01<00:04,  5.17filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447818000013/0000764478-18-000013-index.htm 10-K 2018-04-02\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447817000008/0000764478-17-000008-index.htm 10-K 2017-03-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  20%|██        | 5/25 [00:01<00:03,  5.93filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447821000068/0000764478-21-000068-index.htm 10-Q 2021-12-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  28%|██▊       | 7/25 [00:01<00:03,  4.90filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447821000060/0000764478-21-000060-index.htm 10-Q 2021-08-31\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447821000039/0000764478-21-000039-index.htm 10-Q 2021-06-04\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447820000062/0000764478-20-000062-index.htm 10-Q 2020-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  40%|████      | 10/25 [00:01<00:02,  7.13filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447820000054/0000764478-20-000054-index.htm 10-Q 2020-08-31\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447820000029/0000764478-20-000029-index.htm 10-Q 2020-05-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  48%|████▊     | 12/25 [00:02<00:02,  4.36filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447819000057/0000764478-19-000057-index.htm 10-Q 2019-12-06\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447819000042/0000764478-19-000042-index.htm 10-Q 2019-09-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  60%|██████    | 15/25 [00:03<00:01,  6.81filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447819000028/0000764478-19-000028-index.htm 10-Q 2019-06-07\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447818000053/0000764478-18-000053-index.htm 10-Q 2018-12-07\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447818000043/0000764478-18-000043-index.htm 10-Q 2018-09-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  72%|███████▏  | 18/25 [00:03<00:01,  5.35filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447818000024/0000764478-18-000024-index.htm 10-Q 2018-06-08\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447817000039/0000764478-17-000039-index.htm 10-Q 2017-12-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  80%|████████  | 20/25 [00:03<00:00,  6.79filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447817000032/0000764478-17-000032-index.htm 10-Q 2017-09-05\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447817000018/0000764478-17-000018-index.htm 10-Q 2017-06-05\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447816000093/0000764478-16-000093-index.htm 10-Q 2016-12-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings:  88%|████████▊ | 22/25 [00:04<00:00,  4.37filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447816000088/0000764478-16-000088-index.htm 10-Q 2016-09-02\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447816000075/0000764478-16-000075-index.htm 10-Q 2016-06-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings: 100%|██████████| 25/25 [00:05<00:00,  6.48filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/764478/000076447815000051/0000764478-15-000051-index.htm 10-Q 2015-12-04\n",
      "https://www.sec.gov/Archives/edgar/data/764478/000076447815000042/0000764478-15-000042-index.htm 10-Q 2015-09-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BBY Fillings: 100%|██████████| 25/25 [00:05<00:00,  4.96filling/s]\n",
      "Downloading AIV Fillings:   0%|          | 0/26 [00:00<?, ?filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000156459021022517/0001564590-21-022517-index.htm 10-K/A 2021-04-30\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000156459021012671/0001564590-21-012671-index.htm 10-K 2021-03-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  12%|█▏        | 3/26 [00:00<00:05,  4.22filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000156459020006053/0001564590-20-006053-index.htm 10-K 2020-02-24\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286419000007/0000922864-19-000007-index.htm 10-K 2019-02-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  19%|█▉        | 5/26 [00:00<00:03,  5.83filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000092286418000006/0000922864-18-000006-index.htm 10-K 2018-03-01\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286417000006/0000922864-17-000006-index.htm 10-K 2017-02-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  23%|██▎       | 6/26 [00:01<00:03,  6.46filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000156459021055777/0001564590-21-055777-index.htm 10-Q 2021-11-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  31%|███       | 8/26 [00:01<00:03,  4.81filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000156459021044377/0001564590-21-044377-index.htm 10-Q 2021-08-16\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000156459021028429/0001564590-21-028429-index.htm 10-Q 2021-05-17\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000156459020049394/0001564590-20-049394-index.htm 10-Q 2020-11-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  42%|████▏     | 11/26 [00:01<00:02,  7.06filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000156459020036228/0001564590-20-036228-index.htm 10-Q 2020-08-04\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000156459020023679/0001564590-20-023679-index.htm 10-Q 2020-05-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  54%|█████▍    | 14/26 [00:02<00:02,  5.34filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000156459019039821/0001564590-19-039821-index.htm 10-Q 2019-11-04\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000156459019031035/0001564590-19-031035-index.htm 10-Q 2019-08-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  58%|█████▊    | 15/26 [00:02<00:01,  5.97filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000092286419000024/0000922864-19-000024-index.htm 10-Q 2019-05-06\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286418000047/0000922864-18-000047-index.htm 10-Q 2018-11-05\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286418000037/0000922864-18-000037-index.htm 10-Q 2018-08-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  73%|███████▎  | 19/26 [00:03<00:01,  5.45filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000092286418000021/0000922864-18-000021-index.htm 10-Q 2018-05-08\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286417000043/0000922864-17-000043-index.htm 10-Q 2017-11-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  77%|███████▋  | 20/26 [00:03<00:01,  5.99filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000092286417000035/0000922864-17-000035-index.htm 10-Q 2017-08-02\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286417000016/0000922864-17-000016-index.htm 10-Q 2017-05-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  81%|████████  | 21/26 [00:04<00:00,  6.57filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000092286416000124/0000922864-16-000124-index.htm 10-Q 2016-10-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  88%|████████▊ | 23/26 [00:04<00:00,  4.17filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000092286416000112/0000922864-16-000112-index.htm 10-Q 2016-07-29\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286416000089/0000922864-16-000089-index.htm 10-Q 2016-04-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings:  96%|█████████▌| 25/26 [00:05<00:00,  5.52filling/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/922864/000092286415000054/0000922864-15-000054-index.htm 10-Q 2015-11-05\n",
      "https://www.sec.gov/Archives/edgar/data/922864/000092286415000033/0000922864-15-000033-index.htm 10-Q 2015-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AIV Fillings: 100%|██████████| 26/26 [00:05<00:00,  5.03filling/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fillings_by_ticker = {}\n",
    "browser = webdriver.Edge(service=EdgeService(EdgeChromiumDriverManager().install()))\n",
    "for ticker, data in sec_data.items():\n",
    "    fillings_by_ticker[ticker] = {}\n",
    "    for index_url, file_type, file_date in tqdm(data, desc='Downloading {} Fillings'.format(ticker), unit='filling'):\n",
    "        print(index_url, file_type, file_date)\n",
    "        if (file_type == '10-K' or file_type == '10-Q'):\n",
    "            file_url = index_url.replace('-index.htm', '.txt').replace('.txtl', '.txt')\n",
    "            fillings_by_ticker[ticker][file_date] = sec_api.get(file_url)\n",
    "with open('fillings_by_ticker_dict', 'wb') as handle:\n",
    "    pickle.dump(fillings_by_ticker, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "with open('fillings_by_ticker_dict', 'rb') as handle:\n",
    "    fillings_by_ticker = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SEC-DOCUMENT>0000922864-16-000124.txt : 20161028\n",
      "<SEC-HEADER>0000922864-16-000124.hdr.sgml : 20161028\n",
      "<ACCEPTANCE-DATETIME>20161028152849\n",
      "ACCESSION NUMBER:\t\t0000922864-16-000124\n",
      "CONFORMED SUBMISSION TYPE:\t10-Q\n",
      "PUBLIC DOCUMENT COUNT:\t\t56\n",
      "CONFORMED PERIOD OF REPORT:\t20160930\n",
      "FILED AS OF DATE:\t\t20161028\n",
      "DATE AS OF CHANGE:\t\t20161028\n",
      "\n",
      "FILER:\n",
      "\n",
      "\tCOMPANY DATA:\t\n",
      "\t\tCOMPANY CONFORMED NAME:\t\t\tAPARTMENT INVESTMENT & MANAGEMENT CO\n",
      "\t\tCENTRAL INDEX KEY:\t\t\t0000922864\n",
      "\t\tSTANDARD INDUSTRIAL CLASSIFICATION:\tREAL ESTATE INVESTMENT TRUSTS [6798]\n",
      "\t\tIRS NUMBER:\t\t\t\t841259577\n",
      "\t\tSTATE OF INCORPORATION:\t\t\tMD\n",
      "\t\tFISCAL YEAR END:\t\t\t1231\n",
      "\n",
      "\tFILING VALUES:\n",
      "\t\tFORM TYPE:\t\t10-Q\n",
      "\t\tSEC ACT:\t\t1934 Act\n",
      "\t\tSEC FILE NUMBER:\t001-13232\n",
      "\t\tFILM NUMBER:\t\t161958364\n",
      "\n",
      "\tBUSINESS ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t4582 SOUTH ULSTER STREET\n",
      "\t\tSTREET 2:\t\tSUITE 1100\n",
      "\t\tCITY:\t\t\tDENVER\n",
      "\t\tSTATE:\t\t\tCO\n",
      "\t\tZIP:\t\t\t80237\n",
      "\t\tBUSINESS PHONE:\t\t3037578101\n",
      "\n",
      "\tMAIL ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t4582 SOUTH ULSTER STREET\n",
      "\t\tSTREET 2:\t\tSUITE 1100\n",
      "\t\tCITY:\t\t\tDENVER\n",
      "\t\tSTATE:\t\t\tCO\n",
      "\t\tZIP:\t\t\t80237\n",
      "\n",
      "FILER:\n",
      "\n",
      "\tCOMPANY DATA:\t\n",
      "\t\tCOMPANY CONFORMED NAME:\t\t\tAIMCO PROPERTIES L.P.\n",
      "\t\tCENTRAL INDEX KEY:\t\t\t0000926660\n",
      "\t\tSTANDARD INDUSTRIAL CLASSIFICATION:\tOPERATORS OF APARTMENT BUILDINGS [6513]\n",
      "\t\tIRS NUMBER:\t\t\t\t841275621\n",
      "\t\tSTATE OF INCORPORATION:\t\t\tDE\n",
      "\t\tFISCAL YEAR END:\t\t\t1231\n",
      "\n",
      "\tFILING VALUES:\n",
      "\t\tFORM TYPE:\t\t10-Q\n",
      "\t\tSEC ACT:\t\t1934 Act\n",
      "\t\tSEC FILE NUMBER:\t000-24497\n",
      "\t\tFILM NUMBER:\t\t161958365\n",
      "\n",
      "\tBUSINESS ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t4582 S ULSTER ST PARKWAY\n",
      "\t\tSTREET 2:\t\tSUITE 1100\n",
      "\t\tCITY:\t\t\tDENVER\n",
      "\t\tSTATE:\t\t\tCO\n",
      "\t\tZIP:\t\t\t80237\n",
      "\t\tBUSINESS PHONE:\t\t3037578101\n",
      "\n",
      "\tMAIL ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t4582 S ULSTER ST PARKWAY\n",
      "\t\tSTREET 2:\t\tSUITE 1100\n",
      "\t\tCITY:\t\t\tDENVER\n",
      "\t\tSTATE:\t\t\tCO\n",
      "\t\tZIP:\t\t\t80237\n",
      "\n",
      "\tFORMER COMPANY:\t\n",
      "\t\tFORMER CONFORMED NAME:\tAIMCO PROPERTIES LP\n",
      "\t\tDATE OF NAME CHANGE:\t19980519\n",
      "</SEC-HEADER>\n",
      "<DOCUMENT>\n",
      "<TYPE>10-Q\n",
      "<SEQUENCE>1\n",
      "<FILENAME>q3201610-q.htm\n",
      "<DESCRIPTION>10-Q Q3 2016\n",
      "<TEXT>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
      "<html>\n",
      "\t<head>\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "print(fillings_by_ticker[\"AIV\"][\"2016-10-28\"][:2000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# ten_ks_by_ticker = {}\n",
    "#\n",
    "# for ticker, filling_documents in filling_documents_by_ticker.items():\n",
    "#     ten_ks_by_ticker[ticker] = []\n",
    "#     for file_date, documents in filling_documents.items():\n",
    "#         for document in documents:\n",
    "#             if get_document_type(document) == '10-k':\n",
    "#                 ten_ks_by_ticker[ticker].append({\n",
    "#                     'cik': cik_lookup[ticker],\n",
    "#                     'file': document,\n",
    "#                     'file_date': file_date})\n",
    "#\n",
    "#\n",
    "# project_helper.print_ten_k_data(ten_ks_by_ticker[example_ticker][:5], ['cik', 'file', 'file_date'])\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# raw_10k = raw_fillings_by_ticker[\"AMZN\"][\"2019-02-01\"]\n",
    "# import re\n",
    "# # Regex to find <DOCUMENT> tags\n",
    "# doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "# doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
    "# # Regex to find <TYPE> tag prceeding any characters, terminating at new line\n",
    "# type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
    "# # Create 3 lists with the span idices for each regex\n",
    "#\n",
    "# ### There are many <Document> Tags in this text file, each as specific exhibit like 10-K, EX-10.17 etc\n",
    "# ### First filter will give us document tag start <end> and document tag end's <start>\n",
    "# ### We will use this to later grab content in between these tags\n",
    "# doc_start_is = [x.end() for x in doc_start_pattern.finditer(raw_10k)]\n",
    "# doc_end_is = [x.start() for x in doc_end_pattern.finditer(raw_10k)]\n",
    "#\n",
    "# ### Type filter is interesting, it looks for <TYPE> with Not flag as new line, ie terminare there, with + sign\n",
    "# ### to look for any char afterwards until new line \\n. This will give us <TYPE> followed Section Name like '10-K'\n",
    "# ### Once we have have this, it returns String Array, below line will with find content after <TYPE> ie, '10-K'\n",
    "# ### as section names\n",
    "# doc_types = [x[len('<TYPE>'):] for x in type_pattern.findall(raw_10k)]\n",
    "# document = {}\n",
    "#\n",
    "# # Create a loop to go through each section type and save only the 10-K section in the dictionary\n",
    "# for doc_type, doc_start, doc_end in zip(doc_types, doc_start_is, doc_end_is):\n",
    "#     if doc_type == '10-K':\n",
    "#         document[doc_type] = raw_10k[doc_start:doc_end]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# # display excerpt the document\n",
    "# document['10-K'][0:500]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# # Write the regex\n",
    "# regex = re.compile(r'(>Item(\\s|&#160;|&nbsp;)(1A|1B|7A|7|8)\\.{0,1})|(ITEM\\s(1A|1B|7A|7|8))')\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# matches = regex.finditer(document['10-K'])\n",
    "#\n",
    "# # Create the dataframe\n",
    "# test_df = pd.DataFrame([(x.group(), x.start(), x.end()) for x in matches])\n",
    "#\n",
    "# test_df.columns = ['item', 'start', 'end']\n",
    "# test_df['item'] = test_df.item.str.lower()\n",
    "#\n",
    "# # Display the dataframe\n",
    "# test_df.head()\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# # Get rid of unnesesary charcters from the dataframe\n",
    "# test_df.replace('&#160;',' ',regex=True,inplace=True)\n",
    "# test_df.replace('&nbsp;',' ',regex=True,inplace=True)\n",
    "# test_df.replace(' ','',regex=True,inplace=True)\n",
    "# test_df.replace('\\.','',regex=True,inplace=True)\n",
    "# test_df.replace('>','',regex=True,inplace=True)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# pos_dat = test_df.sort_values('start', ascending=True).drop_duplicates(subset=['item'], keep='last')\n",
    "# pos_dat.set_index('item', inplace=True)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# pos_dat\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# document['10-K']\n",
    "# #Get Item 1a\n",
    "# item_1a_raw = document['10-K'][pos_dat['start'].loc['item1a']:pos_dat['start'].loc['item1b']]\n",
    "# #item_1b_raw = document['10-K'][pos_dat['start'].loc['item1b']:pos_dat['start'].loc['item7a']]\n",
    "# item_7_raw = document['10-K'][pos_dat['start'].loc['item7']:pos_dat['start'].loc['item7a']]\n",
    "# item_7a_raw = document['10-K'][pos_dat['start'].loc['item7a']:pos_dat['start'].loc['item8']]\n",
    "# #item_8_raw = document['10-K'][pos_dat['start'].loc['item8']:]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# \"a\"+\" \"+\"b\"\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# item_content = BeautifulSoup(item_1a_raw + item_7_raw + item_7a_raw, 'lxml')\n",
    "# print(item_content.get_text(\"\\n\\n\"))\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# len(item_content.get_text(\"\\n\\n\"))\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Documents\n",
    "With theses fillings downloaded, we want to break them into their associated documents. These documents are sectioned off in the fillings with the tags `<DOCUMENT>` for the start of each document and `</DOCUMENT>` for the end of each document. There's no overlap with these documents, so each `</DOCUMENT>` tag should come after the `<DOCUMENT>` with no `<DOCUMENT>` tag in between.\n",
    "\n",
    "Implement `get_documents` to return a list of these documents from a filling. Make sure not to include the tag in the returned document text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# import re\n",
    "#\n",
    "#\n",
    "# def get_documents(text):\n",
    "#     \"\"\"\n",
    "#     Extract the documents from the text\n",
    "#\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str\n",
    "#         The text with the document strings inside\n",
    "#\n",
    "#     Returns\n",
    "#     -------\n",
    "#     extracted_docs : list of str\n",
    "#         The document strings found in `text`\n",
    "#     \"\"\"\n",
    "#\n",
    "#     # TODO: Implement\n",
    "#     extracted_docs = []\n",
    "#\n",
    "#     doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "#     doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
    "#\n",
    "#     doc_start_is = [x.end() for x in doc_start_pattern.finditer(text)]\n",
    "#     doc_end_is = [x.start() for x in doc_end_pattern.finditer(text)]\n",
    "#\n",
    "#     for doc_start_i, doc_end_i in zip(doc_start_is, doc_end_is):\n",
    "#             extracted_docs.append(text[doc_start_i:doc_end_i])\n",
    "#\n",
    "#     return extracted_docs\n",
    "#\n",
    "#\n",
    "# project_tests.test_get_documents(get_documents)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the `get_documents` function implemented, let's extract all the documents."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# filling_documents_by_ticker = {}\n",
    "#\n",
    "# for ticker, raw_fillings in raw_fillings_by_ticker.items():\n",
    "#     filling_documents_by_ticker[ticker] = {}\n",
    "#     for file_date, filling in tqdm(raw_fillings.items(), desc='Getting Documents from {} Fillings'.format(ticker), unit='filling'):\n",
    "#         filling_documents_by_ticker[ticker][file_date] = get_documents(filling)\n",
    "#\n",
    "#\n",
    "# print('\\n\\n'.join([\n",
    "#     'Document {} Filed on {}:\\n{}...'.format(doc_i, file_date, doc[:200])\n",
    "#     for file_date, docs in filling_documents_by_ticker[example_ticker].items()\n",
    "#     for doc_i, doc in enumerate(docs)][:3]))\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Document Types\n",
    "Now that we have all the documents, we want to find the 10-k form in this 10-k filing. Implement the `get_document_type` function to return the type of document given. The document type is located on a line with the `<TYPE>` tag. For example, a form of type \"TEST\" would have the line `<TYPE>TEST`. Make sure to return the type as lowercase, so this example would be returned as \"test\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# def get_document_type(doc):\n",
    "#     type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
    "#\n",
    "#     doc_type = type_pattern.findall(doc)[0][len('<TYPE>'):]\n",
    "#\n",
    "#     return doc_type.lower()\n",
    "#\n",
    "#\n",
    "# project_tests.test_get_document_type(get_document_type)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the `get_document_type` function, we'll filter out all non 10-k documents."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# ten_ks_by_ticker = {}\n",
    "#\n",
    "# for ticker, filling_documents in filling_documents_by_ticker.items():\n",
    "#     ten_ks_by_ticker[ticker] = []\n",
    "#     for file_date, documents in filling_documents.items():\n",
    "#         for document in documents:\n",
    "#             if get_document_type(document) == '10-k':\n",
    "#                 ten_ks_by_ticker[ticker].append({\n",
    "#                     'cik': cik_lookup[ticker],\n",
    "#                     'file': document,\n",
    "#                     'file_date': file_date})\n",
    "#\n",
    "#\n",
    "# project_helper.print_ten_k_data(ten_ks_by_ticker[example_ticker][:5], ['cik', 'file', 'file_date'])\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# def remove_html_tags(text):\n",
    "#     text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "#\n",
    "#     return text\n",
    "#\n",
    "#\n",
    "# def clean_text(text):\n",
    "#     text = text.lower()\n",
    "#     text = remove_html_tags(text)\n",
    "#\n",
    "#     return text\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the `clean_text` function, we'll clean up all the documents."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# for ticker, ten_ks in ten_ks_by_ticker.items():\n",
    "#     for ten_k in tqdm(ten_ks, desc='Cleaning {} 10-Ks'.format(ticker), unit='10-K'):\n",
    "#         ten_k['file_clean'] = clean_text(ten_k['file'])\n",
    "#\n",
    "#\n",
    "# project_helper.print_ten_k_data(ten_ks_by_ticker[example_ticker][:5], ['file_clean'])\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lemmatize\n",
    "With the text cleaned up, it's time to distill the verbs down. Implement the `lemmatize_words` function to lemmatize verbs in the list of words provided."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.corpus import wordnet\n",
    "#\n",
    "#\n",
    "# def lemmatize_words(words):\n",
    "#     \"\"\"\n",
    "#     Lemmatize words\n",
    "#\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     words : list of str\n",
    "#         List of words\n",
    "#\n",
    "#     Returns\n",
    "#     -------\n",
    "#     lemmatized_words : list of str\n",
    "#         List of lemmatized words\n",
    "#     \"\"\"\n",
    "#\n",
    "#     # TODO: Implement\n",
    "#     lemmatized_words = [WordNetLemmatizer().lemmatize(word, 'v') for word in words]\n",
    "#\n",
    "#     return lemmatized_words\n",
    "#\n",
    "#\n",
    "# project_tests.test_lemmatize_words(lemmatize_words)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the `lemmatize_words` function implemented, let's lemmatize all the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# ten_ks[0][\"file_clean\"] = item_content.get_text(\"\\n\\n\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# word_pattern = re.compile('\\w+')\n",
    "#\n",
    "# for ticker, ten_ks in ten_ks_by_ticker.items():\n",
    "#     for ten_k in tqdm(ten_ks, desc='Lemmatize {} 10-Ks'.format(ticker), unit='10-K'):\n",
    "#         ten_k['file_lemma'] = lemmatize_words(word_pattern.findall(ten_k['file_clean']))\n",
    "#\n",
    "#\n",
    "# project_helper.print_ten_k_data(ten_ks_by_ticker[example_ticker][:5], ['file_lemma'])\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove Stopwords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "#\n",
    "#\n",
    "# lemma_english_stopwords = lemmatize_words(stopwords.words('english'))\n",
    "#\n",
    "# for ticker, ten_ks in ten_ks_by_ticker.items():\n",
    "#     for ten_k in tqdm(ten_ks, desc='Remove Stop Words for {} 10-Ks'.format(ticker), unit='10-K'):\n",
    "#         ten_k['file_lemma'] = [word for word in ten_k['file_lemma'] if word not in lemma_english_stopwords]\n",
    "#\n",
    "#\n",
    "# print('Stop Words Removed')\n",
    "# if (\"7A\" in ten_ks[0]['file_lemma']):\n",
    "#     print(\"Element Exists\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# ten_ks[0]['file_lemma']\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# len(ten_ks[0]['file_lemma'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "Python (base)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}